{"cells":[{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2643,"status":"ok","timestamp":1685784281922,"user":{"displayName":"John Wong","userId":"09424152075021451045"},"user_tz":-480},"id":"iQQYzytOcXQ9","outputId":"bc95fa02-0d52-484b-8d28-4c23f6caa318"},"outputs":[{"name":"stdout","output_type":"stream","text":["He remained okay while his brothers argued\n","{'input_ids': tensor([[   0,  894, 2442, 8578,  150,   39, 5396, 3811,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n","SequenceClassifierOutput(loss=None, logits=tensor([[-1.6209,  1.1510,  0.4472]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n","[0.04016365 0.64215165 0.3176847 ]\n","Negative 0.040163655\n","Positive 0.64215165\n","Neutral 0.3176847\n"]}],"source":["from transformers.pipelines.base import AutoModel\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from scipy.special import softmax\n","\n","# tweet = '@stev is a handsome and nice guy @ ☺️ https://www.abc.com'\n","# tweet = 'Contractor has a very bad work progress'\n","tweet = 'He remained okay while his brothers argued'\n","\n","# preprocess tweet\n","\n","tweet_words = []\n","\n","for word in tweet.split(' '):\n","  if word.startswith('@') and len(word) > 1:\n","    word = '@user'\n","  \n","  elif word.startswith('https') and len(word) >= 1:\n","    word = 'http'\n","\n","  tweet_words.append(word)\n","\n","tweet_proc = \" \".join(tweet_words)\n","\n","print(tweet_proc)\n","\n","# load the model and tokenizer \n","\n","roberta = 'cardiffnlp/twitter-roberta-base-sentiment'\n","\n","model = AutoModelForSequenceClassification.from_pretrained(roberta)\n","\n","tokenizer = AutoTokenizer.from_pretrained(roberta)\n","\n","# labels = ['Negative', 'Neutral', 'Positive']\n","labels = ['Negative', 'Positive', 'Neutral']\n","\n","# sentiment analysis\n","encoded_tweet = tokenizer(tweet_proc, return_tensors='pt')\n","print(encoded_tweet)\n","\n","\n","# output = model(encoded_tweet['input_ids'], encoded_tweet['attention_mask'])\n","\n","# instead of using above the code, we can shorten it by using this following code\n","# it will still do the same as above but we do not need to type so many\n","output = model(**encoded_tweet)\n","print(output)\n","\n","\n","scores = output[0][0].detach().numpy()\n","scores = softmax(scores)\n","print(scores)\n","\n","for i in range(len(scores)):\n","  l = labels[i]\n","  s = scores[i]\n","  print(l,s)\n","\n","\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMSLCfzvhxMWWgwLNYyvEGD","mount_file_id":"1ZN5AlxQWsZDzV4tqfptLyAhAEDf2SbmW","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
